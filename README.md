# gcp_osm
Load openstreetmap to GCP bigquery

## Step 0: Download OpenStreetMap release from source site
Source file is available on [Planet OSM](https://planet.openstreetmap.org/). The entire full pbf file should be downloaded beforehand.

## Step 1: Load GDAL datasets
(Backgrounds please see [this link](https://gdal.org/drivers/vector/osm.html))
GDAL datasets contain 5 layers:
* points : "node" features that have significant tags attached.
* lines : "way" features that are recognized as non-area.
* multilinestrings : "relation" features that form a multilinestring(type = 'multilinestring' or type = 'route').
* multipolygons : "relation" features that form a multipolygon (type = 'multipolygon' or type = 'boundary'), and "way" features that are recognized as area.
* other_relations : "relation" features that do not belong to the above 2 layers.

### Prerequisites
On your local machine you will firstly need to [install GDAL](https://gdal.org/download.html), recommend to install it with Anaconda.
Within GDAL suite, `ogr2ogr` will be responsible for generating these datasets.

### Step 1.1: Generate CSV files of 5 GDAL datasets
Input: PBF file as geospatial info source, `osmconf.ini` as configuration
The command should be like:

`ogr2ogr -skipfailures -f CSV <path_of_output_csv> <path_of_input_pbf_file> --config OSM_CONFIG_FILE <path_of_osmconf.ini> --config OGR_INTERLEAVED_READING YES --config GDAL_CACHEMAX 20000 --config OSM_MAX_TMPFILE_SIZE 40000 -dialect sqlite -sql "select AsGeoJSON(geometry) AS geometry, osm_id,NULL AS osm_way_id,osm_version,osm_timestamp, replace(all_tags,X'0A','') as all_tags from <layer_type> where ST_IsValid(geometry) = 1"`

* `GDAL_CACHEMAX`: in MB, is the maximum reserved RAM for GDAL. e.g. `20000` means 20,000MB.
* `OSM_MAX_TMPFILE_SIZE`: in MB, is the maximum reserved RAM for OSM temp files. e.g. `40000` means 40,000MB.

(Note that `GDAL_CACHEMAX` and `OSM_MAX_TMPFILE_SIZE` are independent respectively, which means in the previous example the RAM occupied would be 60,000MB. Please ensure the machine has corresponding resources.)

For `multipolygons` layer especially the sql would be different: substituting `NULL as osm_way_id` with `osm_way_id`, which means osm_way_id is present only for `multipolygon` layer.

### Step 1.2: Transform the CSV files into JSONL
BigQuery accepts [GeoJSON](https://cloud.google.com/bigquery/docs/geospatial-data#loading_geojson_data) as the source. This step converts CSV files generated by the previous step to GeoJSON format.
Suggest to use perl script as it's much faster. The script is copied from [geo-openstreetmap](https://github.com/gcp-pdp/geo-openstreetmap/tree/master/tasks_docker_images/osm_to_features/src/csv_to_json). For machines don't support perl or are not able to install perl dependencies, use python script, but will be much slower.
Note that you need to run below dependencies for perl script.

`cpan JSON`
`cpan Text::CSV::Encoded`

The usage for converting: `./csv-to-json.sh <the_path_containing_csv_files> <py|perl>`
